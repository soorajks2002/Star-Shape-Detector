{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v8UfQjbGoIH"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA1DIq5OpfDE",
        "outputId": "7524f811-eb6c-4e9e-bb24-4213228b8e6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 67051, done.\u001b[K\n",
            "remote: Total 67051 (delta 0), reused 0 (delta 0), pack-reused 67051\u001b[K\n",
            "Receiving objects: 100% (67051/67051), 576.32 MiB | 30.21 MiB/s, done.\n",
            "Resolving deltas: 100% (47075/47075), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJjMHbnDs3Tv",
        "outputId": "32323a58-7244-441c-b443-e8c0e92f040c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.35.0-cp37-cp37m-manylinux2010_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.26)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 42.5 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 54.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 43.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.1 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.23.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 51.7 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.10)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.5.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1684828 sha256=5d9e4237bec73c6c0ad8ff75007a7cc235538e501d5b705a14b68b9d84e7208c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3l7m021u/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=33658df1415f2924a26a5637dbb22211f40fe4910d3295dbe4a30ca68457885f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=f93d89bf4cddb66ab279787eefecf655b92fd8fc8cd776ffbc700ff5e4c435b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=1e1cd36ad21653b8ccda7f9a6c29bbe482d9895a0b7abfae618ec5fe7d10b9b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=2dd721a480bc8751bb1f62d61c2de8d3dc238b654bfaa22db091eaa75f1cde8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.1\n",
            "    Uninstalling pymongo-4.0.1:\n",
            "      Successfully uninstalled pymongo-4.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.35.0 avro-python3-1.10.2 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.5 portalocker-2.3.2 proto-plus-1.19.8 protobuf-3.19.3 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-6.0 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqWo6z4xGoIK",
        "outputId": "9ca8cdcd-f4bf-4926-f2a5-63d45b276874",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-01-16 15:20:55.152706: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0116 15:20:55.624343 140324245215104 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.22s\n",
            "I0116 15:20:55.954348 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.72s\n",
            "I0116 15:20:56.673990 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.72s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
            "I0116 15:20:57.016095 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.33s\n",
            "I0116 15:20:57.351479 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.31s\n",
            "I0116 15:20:59.660972 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.31s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0116 15:20:59.662175 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0116 15:20:59.690610 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0116 15:20:59.707973 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0116 15:20:59.727032 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "I0116 15:20:59.848738 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "I0116 15:20:59.972913 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
            "I0116 15:21:00.103719 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "I0116 15:21:00.227844 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
            "I0116 15:21:00.359299 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0116 15:21:00.395814 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0116 15:21:00.626857 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0116 15:21:00.627104 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0116 15:21:00.627233 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0116 15:21:00.629954 140324245215104 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0116 15:21:00.649912 140324245215104 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0116 15:21:00.650100 140324245215104 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0116 15:21:00.737251 140324245215104 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0116 15:21:00.737471 140324245215104 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0116 15:21:00.930394 140324245215104 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0116 15:21:00.930628 140324245215104 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0116 15:21:01.119395 140324245215104 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0116 15:21:01.119608 140324245215104 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0116 15:21:01.611572 140324245215104 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0116 15:21:01.611861 140324245215104 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0116 15:21:01.920341 140324245215104 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0116 15:21:01.920570 140324245215104 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0116 15:21:02.318839 140324245215104 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0116 15:21:02.319068 140324245215104 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0116 15:21:02.411704 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0116 15:21:02.450453 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:02.517237 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0116 15:21:02.517452 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0116 15:21:02.517558 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0116 15:21:02.519763 140324245215104 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0116 15:21:02.538862 140324245215104 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0116 15:21:02.539045 140324245215104 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0116 15:21:02.689238 140324245215104 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0116 15:21:02.689447 140324245215104 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0116 15:21:02.967779 140324245215104 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0116 15:21:02.968001 140324245215104 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0116 15:21:03.266491 140324245215104 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0116 15:21:03.266700 140324245215104 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0116 15:21:03.660021 140324245215104 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0116 15:21:03.660233 140324245215104 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0116 15:21:04.062737 140324245215104 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0116 15:21:04.062936 140324245215104 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0116 15:21:04.543904 140324245215104 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0116 15:21:04.544101 140324245215104 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0116 15:21:04.721295 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0116 15:21:04.761202 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:04.845672 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0116 15:21:04.845885 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0116 15:21:04.845989 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0116 15:21:04.848412 140324245215104 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0116 15:21:04.868163 140324245215104 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0116 15:21:04.868297 140324245215104 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0116 15:21:05.016068 140324245215104 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0116 15:21:05.016281 140324245215104 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0116 15:21:05.298951 140324245215104 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0116 15:21:05.299155 140324245215104 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0116 15:21:05.579286 140324245215104 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0116 15:21:05.579504 140324245215104 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0116 15:21:05.965251 140324245215104 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0116 15:21:05.965464 140324245215104 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0116 15:21:06.345797 140324245215104 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0116 15:21:06.345998 140324245215104 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0116 15:21:07.029490 140324245215104 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0116 15:21:07.029742 140324245215104 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0116 15:21:07.216403 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0116 15:21:07.251854 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:07.328250 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0116 15:21:07.328438 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0116 15:21:07.328578 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0116 15:21:07.330648 140324245215104 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0116 15:21:07.349624 140324245215104 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0116 15:21:07.349781 140324245215104 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0116 15:21:07.499447 140324245215104 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0116 15:21:07.499694 140324245215104 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0116 15:21:07.791590 140324245215104 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0116 15:21:07.791863 140324245215104 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0116 15:21:08.089025 140324245215104 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0116 15:21:08.089238 140324245215104 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0116 15:21:08.593058 140324245215104 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0116 15:21:08.593254 140324245215104 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0116 15:21:09.076792 140324245215104 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0116 15:21:09.077038 140324245215104 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0116 15:21:09.675278 140324245215104 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0116 15:21:09.675564 140324245215104 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0116 15:21:09.865732 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0116 15:21:09.912015 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:09.995749 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0116 15:21:09.995939 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0116 15:21:09.996075 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0116 15:21:09.998287 140324245215104 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0116 15:21:10.017625 140324245215104 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0116 15:21:10.017812 140324245215104 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0116 15:21:10.174754 140324245215104 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0116 15:21:10.174960 140324245215104 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0116 15:21:10.559179 140324245215104 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0116 15:21:10.559364 140324245215104 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0116 15:21:10.942322 140324245215104 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0116 15:21:10.942527 140324245215104 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0116 15:21:11.515737 140324245215104 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0116 15:21:11.516004 140324245215104 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0116 15:21:12.093647 140324245215104 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0116 15:21:12.093877 140324245215104 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0116 15:21:12.889376 140324245215104 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0116 15:21:12.889608 140324245215104 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0116 15:21:13.363014 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0116 15:21:13.396786 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:13.499931 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0116 15:21:13.500122 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0116 15:21:13.500242 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0116 15:21:13.502178 140324245215104 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0116 15:21:13.522048 140324245215104 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0116 15:21:13.522191 140324245215104 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0116 15:21:13.742553 140324245215104 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0116 15:21:13.742761 140324245215104 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0116 15:21:14.228943 140324245215104 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0116 15:21:14.229181 140324245215104 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0116 15:21:14.761883 140324245215104 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0116 15:21:14.762102 140324245215104 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0116 15:21:15.514844 140324245215104 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0116 15:21:15.515113 140324245215104 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0116 15:21:16.345766 140324245215104 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0116 15:21:16.346059 140324245215104 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0116 15:21:17.270859 140324245215104 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0116 15:21:17.271054 140324245215104 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0116 15:21:17.553566 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0116 15:21:17.592154 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:17.697398 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0116 15:21:17.697580 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0116 15:21:17.697725 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0116 15:21:17.699872 140324245215104 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0116 15:21:17.717911 140324245215104 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0116 15:21:17.718066 140324245215104 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0116 15:21:17.958402 140324245215104 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0116 15:21:17.958612 140324245215104 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0116 15:21:18.533059 140324245215104 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0116 15:21:18.533253 140324245215104 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0116 15:21:19.105066 140324245215104 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0116 15:21:19.105354 140324245215104 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0116 15:21:19.846095 140324245215104 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0116 15:21:19.846295 140324245215104 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0116 15:21:20.904079 140324245215104 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0116 15:21:20.904296 140324245215104 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0116 15:21:21.955618 140324245215104 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0116 15:21:21.955985 140324245215104 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0116 15:21:22.264915 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0116 15:21:22.298732 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0116 15:21:22.419146 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0116 15:21:22.419337 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0116 15:21:22.419448 140324245215104 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0116 15:21:22.421361 140324245215104 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0116 15:21:22.439483 140324245215104 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0116 15:21:22.439629 140324245215104 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0116 15:21:22.726840 140324245215104 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0116 15:21:22.727049 140324245215104 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0116 15:21:23.397690 140324245215104 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0116 15:21:23.397924 140324245215104 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0116 15:21:24.076128 140324245215104 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0116 15:21:24.076328 140324245215104 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0116 15:21:25.044820 140324245215104 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0116 15:21:25.045011 140324245215104 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0116 15:21:26.012525 140324245215104 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0116 15:21:26.012754 140324245215104 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0116 15:21:27.572059 140324245215104 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0116 15:21:27.572269 140324245215104 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0116 15:21:27.985925 140324245215104 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0116 15:21:28.021177 140324245215104 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.77s\n",
            "I0116 15:21:28.168154 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.77s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0116 15:21:28.175650 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0116 15:21:28.177886 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0116 15:21:28.178507 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0116 15:21:28.180298 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0116 15:21:28.182166 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0116 15:21:28.182753 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0116 15:21:28.183949 140324245215104 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 35.453s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Gedrj2qLGoIK",
        "outputId": "323be6be-0562-43f4-b095-474ffce926d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.23.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "collapsed": true,
        "id": "RMUSmztKGoIK",
        "outputId": "04f2726c-2bad-49d6-bb55-3379da096773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: protobuf 3.19.3\n",
            "Uninstalling protobuf-3.19.3:\n",
            "  Successfully uninstalled protobuf-3.19.3\n",
            "Found existing installation: matplotlib 3.2.2\n",
            "Uninstalling matplotlib-3.2.2:\n",
            "  Successfully uninstalled matplotlib-3.2.2\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-3.19.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting matplotlib==3.2\n",
            "  Downloading matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 13.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.19.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMo4cHmXGoIL"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt1nZB6MGoIL",
        "outputId": "6365899f-f2f4-4ab7-ff2c-8f06d063a1f5",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.35.0\n",
            "appdirs                       1.4.4\n",
            "argcomplete                   2.0.0\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.11.4\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.4.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.3\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        4.1.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.2\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.10\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.10.8\n",
            "cffi                          1.15.0\n",
            "cftime                        1.5.1.1\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.10\n",
            "click                         7.1.2\n",
            "cloudpickle                   1.3.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorama                      0.4.4\n",
            "colorcet                      3.0.0\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.3.2\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.2.7\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.26\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.6\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.293\n",
            "easydict                      1.9\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.3\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastavro                      1.4.9\n",
            "fastdtw                       0.3.4\n",
            "fastprogress                  1.0.0\n",
            "fastrlock                     0.8\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.4.2\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   2.0\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         3.6.4\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.26.3\n",
            "google-api-python-client      1.12.8\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.0\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.54.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.2\n",
            "grpcio                        1.43.0\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.6.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.2\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.7\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.3.0\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.10.0\n",
            "importlib-resources           5.4.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2022.0.1\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.6.5\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.2.25\n",
            "jaxlib                        0.1.71+cuda111\n",
            "jdcal                         1.4.1\n",
            "jedi                          0.18.1\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.9.1\n",
            "jupyterlab-pygments           0.1.2\n",
            "jupyterlab-widgets            1.0.2\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.6\n",
            "keras                         2.7.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.3.2\n",
            "korean-lunar-calendar         0.2.1\n",
            "libclang                      12.0.0\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.6\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.0\n",
            "matplotlib-inline             0.1.3\n",
            "matplotlib-venn               0.11.6\n",
            "missingno                     0.5.0\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.12.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.3\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.10\n",
            "murmurhash                    1.0.6\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.5.9\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.1.3\n",
            "nest-asyncio                  1.5.4\n",
            "netCDF4                       1.5.8\n",
            "networkx                      2.6.3\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.8.1\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.1\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.5.5.62\n",
            "openpyxl                      2.5.9\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.6.5\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.1.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.0\n",
            "parso                         0.8.3\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.2\n",
            "pep517                        0.12.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        4.4.1\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.5.2\n",
            "portalocker                   2.3.2\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.6\n",
            "prettytable                   3.0.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.12.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "proto-plus                    1.19.8\n",
            "protobuf                      3.19.3\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       3.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.4\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.3.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.5\n",
            "pyparsing                     3.0.6\n",
            "pyrsistent                    0.18.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.15\n",
            "python-slugify                5.0.2\n",
            "python-utils                  3.0.0\n",
            "pytz                          2018.9\n",
            "pyviz-comms                   2.1.0\n",
            "PyWavelets                    1.2.0\n",
            "PyYAML                        6.0\n",
            "pyzmq                         22.3.0\n",
            "qdldl                         0.1.5.post0\n",
            "qtconsole                     5.2.2\n",
            "QtPy                          2.0.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.27.1\n",
            "requests-oauthlib             1.3.0\n",
            "resampy                       0.2.2\n",
            "retrying                      1.3.3\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.8\n",
            "sacrebleu                     2.0.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.0.1\n",
            "seaborn                       0.11.2\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.96\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.0\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.29\n",
            "sqlparse                      0.4.2\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.4.4\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tensorboard                   2.7.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.7.0\n",
            "tensorflow-addons             0.15.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.7.0\n",
            "tensorflow-gcs-config         2.7.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.23.1\n",
            "tensorflow-io-gcs-filesystem  0.23.1\n",
            "tensorflow-metadata           1.5.0\n",
            "tensorflow-model-optimization 0.7.0\n",
            "tensorflow-probability        0.15.0\n",
            "tensorflow-text               2.7.3\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.12.1\n",
            "testpath                      0.5.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.7.0\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "threadpoolctl                 3.0.0\n",
            "tifffile                      2021.11.2\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.0\n",
            "toolz                         0.11.2\n",
            "torch                         1.10.0+cu111\n",
            "torchaudio                    0.10.0+cu111\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.11.0\n",
            "torchvision                   0.11.1+cu111\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.62.3\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.10.0.2\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.9.0\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            3.5.2\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.13.3\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.3.post1\n",
            "zict                          2.0.0\n",
            "zipp                          3.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "c7d6eb65-c255-4fd7-e0cf-6ae1a42c06ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-01-16 15:23:27--  http://%7Bpretrained_model_url%7D/\n",
            "Resolving {pretrained_model_url} ({pretrained_model_url})... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘{pretrained_model_url}’\n",
            "mv: cannot stat '{PRETRAINED_MODEL_NAME+.tar.gz}': No such file or directory\n",
            "/bin/bash: line 0: cd: {paths[PRETRAINED_MODEL_PATH]}: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'star', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpb_BVUpfDD",
        "outputId": "f83fe756-fe68-4fa0-c1ce-7d02d22aad48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "60320acf-5f21-4f0f-ec2f-40f7f9bfa167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "10179801-0496-4080-dd84-ab7533b02373"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL0Ifny4KJtz",
        "outputId": "5c254239-1a0c-4f21-fd1c-d18f4274b42e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.62\n",
            "Uninstalling opencv-python-headless-4.5.5.62:\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.62\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.5.5.62\n"
          ]
        }
      ],
      "source": [
        "! pip uninstall opencv-python-headless -y\n",
        "! pip install opencv-python --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "e4ff2a78-4173-4819-b890-a73cc0d5b9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "bfd277d4-bcfb-4505-8853-7d0548c327eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-16 15:24:25.482593: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0116 15:24:25.486146 140360819148672 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0116 15:24:25.492291 140360819148672 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0116 15:24:25.492587 140360819148672 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0116 15:24:25.533311 140360819148672 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0116 15:24:25.545104 140360819148672 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0116 15:24:25.545318 140360819148672 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0116 15:24:25.545466 140360819148672 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0116 15:24:25.545602 140360819148672 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0116 15:24:25.553182 140360819148672 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0116 15:24:25.586554 140360819148672 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0116 15:24:34.614095 140360819148672 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0116 15:24:38.532763 140360819148672 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0116 15:24:40.634560 140360819148672 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-01-16 15:24:43.935933: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.718751 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.720230 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.722826 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.723883 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.726540 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.727784 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.730396 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.731519 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.734117 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0116 15:25:15.735218 140360819148672 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0116 15:25:16.673394 140355886819072 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.572s\n",
            "I0116 15:26:13.271643 140360819148672 model_lib_v2.py:707] Step 100 per-step time 0.572s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15733741,\n",
            " 'Loss/localization_loss': 0.21939936,\n",
            " 'Loss/regularization_loss': 0.15387301,\n",
            " 'Loss/total_loss': 0.5306098,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0116 15:26:13.272034 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.15733741,\n",
            " 'Loss/localization_loss': 0.21939936,\n",
            " 'Loss/regularization_loss': 0.15387301,\n",
            " 'Loss/total_loss': 0.5306098,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.194s\n",
            "I0116 15:26:32.630123 140360819148672 model_lib_v2.py:707] Step 200 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15077142,\n",
            " 'Loss/localization_loss': 0.10384856,\n",
            " 'Loss/regularization_loss': 0.15362798,\n",
            " 'Loss/total_loss': 0.40824795,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0116 15:26:32.630496 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.15077142,\n",
            " 'Loss/localization_loss': 0.10384856,\n",
            " 'Loss/regularization_loss': 0.15362798,\n",
            " 'Loss/total_loss': 0.40824795,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.194s\n",
            "I0116 15:26:52.064150 140360819148672 model_lib_v2.py:707] Step 300 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0927169,\n",
            " 'Loss/localization_loss': 0.05120585,\n",
            " 'Loss/regularization_loss': 0.15327616,\n",
            " 'Loss/total_loss': 0.2971989,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0116 15:26:52.064523 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.0927169,\n",
            " 'Loss/localization_loss': 0.05120585,\n",
            " 'Loss/regularization_loss': 0.15327616,\n",
            " 'Loss/total_loss': 0.2971989,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.194s\n",
            "I0116 15:27:11.425142 140360819148672 model_lib_v2.py:707] Step 400 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0879717,\n",
            " 'Loss/localization_loss': 0.05678816,\n",
            " 'Loss/regularization_loss': 0.15286675,\n",
            " 'Loss/total_loss': 0.2976266,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0116 15:27:11.425514 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.0879717,\n",
            " 'Loss/localization_loss': 0.05678816,\n",
            " 'Loss/regularization_loss': 0.15286675,\n",
            " 'Loss/total_loss': 0.2976266,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.196s\n",
            "I0116 15:27:31.036824 140360819148672 model_lib_v2.py:707] Step 500 per-step time 0.196s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.085793555,\n",
            " 'Loss/localization_loss': 0.068773605,\n",
            " 'Loss/regularization_loss': 0.15242688,\n",
            " 'Loss/total_loss': 0.30699402,\n",
            " 'learning_rate': 0.053333}\n",
            "I0116 15:27:31.037202 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.085793555,\n",
            " 'Loss/localization_loss': 0.068773605,\n",
            " 'Loss/regularization_loss': 0.15242688,\n",
            " 'Loss/total_loss': 0.30699402,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.195s\n",
            "I0116 15:27:50.560759 140360819148672 model_lib_v2.py:707] Step 600 per-step time 0.195s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09073495,\n",
            " 'Loss/localization_loss': 0.04715125,\n",
            " 'Loss/regularization_loss': 0.15190475,\n",
            " 'Loss/total_loss': 0.28979093,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0116 15:27:50.561213 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.09073495,\n",
            " 'Loss/localization_loss': 0.04715125,\n",
            " 'Loss/regularization_loss': 0.15190475,\n",
            " 'Loss/total_loss': 0.28979093,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.194s\n",
            "I0116 15:28:09.943370 140360819148672 model_lib_v2.py:707] Step 700 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0842989,\n",
            " 'Loss/localization_loss': 0.053581625,\n",
            " 'Loss/regularization_loss': 0.15135151,\n",
            " 'Loss/total_loss': 0.28923205,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0116 15:28:09.943773 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.0842989,\n",
            " 'Loss/localization_loss': 0.053581625,\n",
            " 'Loss/regularization_loss': 0.15135151,\n",
            " 'Loss/total_loss': 0.28923205,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.195s\n",
            "I0116 15:28:29.445810 140360819148672 model_lib_v2.py:707] Step 800 per-step time 0.195s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06583206,\n",
            " 'Loss/localization_loss': 0.025812982,\n",
            " 'Loss/regularization_loss': 0.15069343,\n",
            " 'Loss/total_loss': 0.24233848,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0116 15:28:29.446241 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.06583206,\n",
            " 'Loss/localization_loss': 0.025812982,\n",
            " 'Loss/regularization_loss': 0.15069343,\n",
            " 'Loss/total_loss': 0.24233848,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.194s\n",
            "I0116 15:28:48.893162 140360819148672 model_lib_v2.py:707] Step 900 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08283652,\n",
            " 'Loss/localization_loss': 0.05069446,\n",
            " 'Loss/regularization_loss': 0.15006174,\n",
            " 'Loss/total_loss': 0.2835927,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0116 15:28:48.893516 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.08283652,\n",
            " 'Loss/localization_loss': 0.05069446,\n",
            " 'Loss/regularization_loss': 0.15006174,\n",
            " 'Loss/total_loss': 0.2835927,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.194s\n",
            "I0116 15:29:08.256789 140360819148672 model_lib_v2.py:707] Step 1000 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13370053,\n",
            " 'Loss/localization_loss': 0.10405606,\n",
            " 'Loss/regularization_loss': 0.1493324,\n",
            " 'Loss/total_loss': 0.387089,\n",
            " 'learning_rate': 0.08}\n",
            "I0116 15:29:08.257194 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.13370053,\n",
            " 'Loss/localization_loss': 0.10405606,\n",
            " 'Loss/regularization_loss': 0.1493324,\n",
            " 'Loss/total_loss': 0.387089,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.198s\n",
            "I0116 15:29:28.042057 140360819148672 model_lib_v2.py:707] Step 1100 per-step time 0.198s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31121552,\n",
            " 'Loss/localization_loss': 0.02281235,\n",
            " 'Loss/regularization_loss': 0.14860074,\n",
            " 'Loss/total_loss': 0.48262858,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0116 15:29:28.042455 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.31121552,\n",
            " 'Loss/localization_loss': 0.02281235,\n",
            " 'Loss/regularization_loss': 0.14860074,\n",
            " 'Loss/total_loss': 0.48262858,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.194s\n",
            "I0116 15:29:47.469325 140360819148672 model_lib_v2.py:707] Step 1200 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09494921,\n",
            " 'Loss/localization_loss': 0.039940324,\n",
            " 'Loss/regularization_loss': 0.14790638,\n",
            " 'Loss/total_loss': 0.2827959,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0116 15:29:47.469709 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.09494921,\n",
            " 'Loss/localization_loss': 0.039940324,\n",
            " 'Loss/regularization_loss': 0.14790638,\n",
            " 'Loss/total_loss': 0.2827959,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.193s\n",
            "I0116 15:30:06.778601 140360819148672 model_lib_v2.py:707] Step 1300 per-step time 0.193s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074722596,\n",
            " 'Loss/localization_loss': 0.023901293,\n",
            " 'Loss/regularization_loss': 0.1470987,\n",
            " 'Loss/total_loss': 0.24572259,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0116 15:30:06.779067 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.074722596,\n",
            " 'Loss/localization_loss': 0.023901293,\n",
            " 'Loss/regularization_loss': 0.1470987,\n",
            " 'Loss/total_loss': 0.24572259,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.194s\n",
            "I0116 15:30:26.158643 140360819148672 model_lib_v2.py:707] Step 1400 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.058455653,\n",
            " 'Loss/localization_loss': 0.02156074,\n",
            " 'Loss/regularization_loss': 0.14628813,\n",
            " 'Loss/total_loss': 0.22630452,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0116 15:30:26.158995 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.058455653,\n",
            " 'Loss/localization_loss': 0.02156074,\n",
            " 'Loss/regularization_loss': 0.14628813,\n",
            " 'Loss/total_loss': 0.22630452,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.195s\n",
            "I0116 15:30:45.616945 140360819148672 model_lib_v2.py:707] Step 1500 per-step time 0.195s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.025564158,\n",
            " 'Loss/localization_loss': 0.013459786,\n",
            " 'Loss/regularization_loss': 0.14549187,\n",
            " 'Loss/total_loss': 0.1845158,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0116 15:30:45.617291 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.025564158,\n",
            " 'Loss/localization_loss': 0.013459786,\n",
            " 'Loss/regularization_loss': 0.14549187,\n",
            " 'Loss/total_loss': 0.1845158,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.196s\n",
            "I0116 15:31:05.219367 140360819148672 model_lib_v2.py:707] Step 1600 per-step time 0.196s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10422196,\n",
            " 'Loss/localization_loss': 0.011531446,\n",
            " 'Loss/regularization_loss': 0.1446869,\n",
            " 'Loss/total_loss': 0.2604403,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0116 15:31:05.219772 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.10422196,\n",
            " 'Loss/localization_loss': 0.011531446,\n",
            " 'Loss/regularization_loss': 0.1446869,\n",
            " 'Loss/total_loss': 0.2604403,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.195s\n",
            "I0116 15:31:24.705840 140360819148672 model_lib_v2.py:707] Step 1700 per-step time 0.195s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055833954,\n",
            " 'Loss/localization_loss': 0.014962867,\n",
            " 'Loss/regularization_loss': 0.14391968,\n",
            " 'Loss/total_loss': 0.2147165,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0116 15:31:24.706199 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.055833954,\n",
            " 'Loss/localization_loss': 0.014962867,\n",
            " 'Loss/regularization_loss': 0.14391968,\n",
            " 'Loss/total_loss': 0.2147165,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.194s\n",
            "I0116 15:31:44.059170 140360819148672 model_lib_v2.py:707] Step 1800 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06432678,\n",
            " 'Loss/localization_loss': 0.011164253,\n",
            " 'Loss/regularization_loss': 0.14310837,\n",
            " 'Loss/total_loss': 0.21859941,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0116 15:31:44.059559 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.06432678,\n",
            " 'Loss/localization_loss': 0.011164253,\n",
            " 'Loss/regularization_loss': 0.14310837,\n",
            " 'Loss/total_loss': 0.21859941,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.194s\n",
            "I0116 15:32:03.481323 140360819148672 model_lib_v2.py:707] Step 1900 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.061945055,\n",
            " 'Loss/localization_loss': 0.012656804,\n",
            " 'Loss/regularization_loss': 0.1423212,\n",
            " 'Loss/total_loss': 0.21692306,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0116 15:32:03.481704 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.061945055,\n",
            " 'Loss/localization_loss': 0.012656804,\n",
            " 'Loss/regularization_loss': 0.1423212,\n",
            " 'Loss/total_loss': 0.21692306,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.194s\n",
            "I0116 15:32:22.874895 140360819148672 model_lib_v2.py:707] Step 2000 per-step time 0.194s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.055465464,\n",
            " 'Loss/localization_loss': 0.021796571,\n",
            " 'Loss/regularization_loss': 0.14152603,\n",
            " 'Loss/total_loss': 0.21878806,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0116 15:32:22.875256 140360819148672 model_lib_v2.py:708] {'Loss/classification_loss': 0.055465464,\n",
            " 'Loss/localization_loss': 0.021796571,\n",
            " 'Loss/regularization_loss': 0.14152603,\n",
            " 'Loss/total_loss': 0.21878806,\n",
            " 'learning_rate': 0.07991781}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "44890865-27d9-411b-e96e-5c4b042b10b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqTV2jGBpfDH",
        "outputId": "095059cc-5849-4b1f-e70a-df830c7f7b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-16 14:54:21.878872: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0116 14:54:21.883908 140129575360384 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0116 14:54:21.884185 140129575360384 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0116 14:54:21.884257 140129575360384 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0116 14:54:21.884332 140129575360384 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0116 14:54:21.884452 140129575360384 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0116 14:54:21.928086 140129575360384 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0116 14:54:21.928435 140129575360384 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0116 14:54:21.928527 140129575360384 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0116 14:54:21.928621 140129575360384 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0116 14:54:21.931037 140129575360384 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0116 14:54:21.964647 140129575360384 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0116 14:54:27.164794 140129575360384 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0116 14:54:28.641866 140129575360384 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "I0116 14:54:31.961753 140129575360384 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
            "I0116 14:54:31.963407 140129575360384 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-3\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0116 14:55:04.242804 140129575360384 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0116 14:55:04.250222 140129575360384 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0116 14:55:04.406995 140129575360384 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Performing evaluation on 32 images.\n",
            "I0116 14:55:13.714013 140129575360384 coco_evaluation.py:293] Performing evaluation on 32 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0116 14:55:13.714431 140129575360384 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0116 14:55:13.719489 140129575360384 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.864\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.862\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.868\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.887\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.887\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.887\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.871\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892\n",
            "INFO:tensorflow:Eval metrics at step 2000\n",
            "I0116 14:55:13.963704 140129575360384 model_lib_v2.py:1015] Eval metrics at step 2000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.863977\n",
            "I0116 14:55:13.965603 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.863977\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
            "I0116 14:55:13.966657 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 1.000000\n",
            "I0116 14:55:13.967521 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0116 14:55:13.968369 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.861881\n",
            "I0116 14:55:13.969215 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.861881\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.867967\n",
            "I0116 14:55:13.970115 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.867967\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.887500\n",
            "I0116 14:55:13.970962 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.887500\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.887500\n",
            "I0116 14:55:13.971738 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.887500\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.887500\n",
            "I0116 14:55:13.972445 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.887500\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0116 14:55:13.973153 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.871429\n",
            "I0116 14:55:13.973956 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.871429\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.892000\n",
            "I0116 14:55:13.974809 140129575360384 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.892000\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.040947\n",
            "I0116 14:55:13.975460 140129575360384 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.040947\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.061569\n",
            "I0116 14:55:13.976130 140129575360384 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.061569\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.142052\n",
            "I0116 14:55:13.976806 140129575360384 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.142052\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.244568\n",
            "I0116 14:55:13.977472 140129575360384 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.244568\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "I0116 14:59:31.974284 140129575360384 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
            "I0116 15:59:31.099863 140129575360384 checkpoint_utils.py:203] Timed-out waiting for a checkpoint.\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = '/content/a (106).jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Tpzn1SMry1yK",
        "outputId": "54096e1c-5bf1-428a-c985-fadff44eb061"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# 10. Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH1aBqu_GoIS",
        "outputId": "e3db91fc-9196-4134-ddaa-2112483fac1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.62\n",
            "Uninstalling opencv-python-headless-4.5.5.62:\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.62\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "o_grs6OGpfDJ",
        "outputId": "73353f97-9d8f-42ad-ff82-b25c8fb03dfc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-32471f95dba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FRAME_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FRAME_HEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Lsp3tCpfDJ",
        "outputId": "c3828529-bf06-4df5-d7f3-145890ec3edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow\\models\\research\\object_detection\\exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config --trained_checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet --output_directory=Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sw1ULgHpfDJ",
        "outputId": "6fd441e1-9fc9-4889-d072-3395c21e40b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-04-03 11:51:42.281339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:51:44.712115: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:51:44.712813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
            "2021-04-03 11:51:44.734951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:51:44.734976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:51:44.738520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:51:44.738545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:51:44.740713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:51:44.741572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:51:44.745641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:51:44.747323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:51:44.747849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:51:44.747917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:51:44.748158: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-03 11:51:44.748975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:51:44.749003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:51:44.749011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:51:44.749017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:51:44.749025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:51:44.749031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:51:44.749036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:51:44.749042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:51:44.749046: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:51:44.749072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:51:45.185363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-03 11:51:45.185385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-03 11:51:45.185389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-03 11:51:45.185509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6461 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
            "2021-04-03 11:51:45.185889: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "WARNING:tensorflow:From D:\\YouTube\\OD\\TFODCourse\\tfod\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\exporter_lib_v2.py:106: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0403 11:51:46.585407 12508 deprecation.py:604] From D:\\YouTube\\OD\\TFODCourse\\tfod\\lib\\site-packages\\object_detection-0.1-py3.7.egg\\object_detection\\exporter_lib_v2.py:106: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x0000022EAD5FA7F0>, because it is not built.\n",
            "W0403 11:51:57.182201 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x0000022EAD5FA7F0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022EB41A6128>, because it is not built.\n",
            "W0403 11:51:57.735328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022EB41A6128>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ECBB91940>, because it is not built.\n",
            "W0403 11:51:57.735328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ECBB91940>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022EC7E820F0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022EC7E820F0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022EBFE87F98>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022EBFE87F98>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED451CDA0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED451CDA0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED451CD30>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED451CD30>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022ED451C390>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022ED451C390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED4510FD0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED4510FD0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ECBB744A8>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ECBB744A8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022ECBB74EB8>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x0000022ECBB74EB8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ECBBCD390>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ECBBCD390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E8C5C0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E8C5C0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ECBBA1CC0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ECBBA1CC0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E8E0B8>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E8E0B8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E9F0F0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E9F0F0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E9F358>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E9F358>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E9F208>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E9F208>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E9FA90>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E9FA90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E9FC18>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E9FC18>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E9FDA0>, because it is not built.\n",
            "W0403 11:51:57.736328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E9FDA0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6EBAF98>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6EBAF98>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6EB6B00>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6EB6B00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6EB6DA0>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6EB6DA0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E98B00>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E98B00>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E982E8>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E982E8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E98C50>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E98C50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E984A8>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E984A8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E98B38>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E98B38>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E42470>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E42470>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED59E30F0>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED59E30F0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED59E3E10>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED59E3E10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E233C8>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E233C8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E23198>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E23198>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED59CA2E8>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED59CA2E8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED59CA3C8>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED59CA3C8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E68278>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E68278>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED450C828>, because it is not built.\n",
            "W0403 11:51:57.737328 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED450C828>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E7B160>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E7B160>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E7B080>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E7B080>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E7B898>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED6E7B898>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E7B8D0>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED6E7B8D0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED58784E0>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED58784E0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED5878198>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x0000022ED5878198>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED5878828>, because it is not built.\n",
            "W0403 11:51:57.738330 12508 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Lambda object at 0x0000022ED5878828>, because it is not built.\n",
            "2021-04-03 11:52:03.707161: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:09.159238 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:09.160238 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:09.160238 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:09.160238 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:11.896544 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:11.896544 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:11.896544 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:11.896544 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:11.896544 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:11.896544 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "W0403 11:52:14.030074 12508 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 155). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:14.174074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:14.174074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:14.174074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:14.174074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:14.368074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:14.368074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:14.368074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:14.368074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:14.368074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:14.368074 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "W0403 11:52:14.738204 12508 save.py:241] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 155). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:17.735654 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C4A8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C7F0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000002309135C6A0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:17.735654 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923746D8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374828>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x0000023092374A90>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "I0403 11:52:17.736654 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C2358>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923C25C0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).\n",
            "INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "I0403 11:52:17.736654 12508 def_function.py:1170] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5208>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B52E8>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x00000230923B5550>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).\n",
            "INFO:tensorflow:Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\saved_model\\assets\n",
            "I0403 11:52:18.462644 12508 builder_impl.py:775] Assets written to: Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\saved_model\\assets\n",
            "INFO:tensorflow:Writing pipeline config file to Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\pipeline.config\n",
            "I0403 11:52:19.186990 12508 config_util.py:254] Writing pipeline config file to Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ6UzY_fpfDK",
        "outputId": "0c84722e-1c2b-4002-d857-80827ade828a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Using cached tensorflowjs-3.3.0-py3-none-any.whl (63 kB)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflowjs) (1.15.0)\n",
            "Collecting tensorflow-hub<0.10,>=0.7.0\n",
            "  Using cached tensorflow_hub-0.9.0-py2.py3-none-any.whl (103 kB)\n",
            "Requirement already satisfied: h5py<3,>=2.8.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.7 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.15.7)\n",
            "Requirement already satisfied: wheel~=0.35 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\typing_extensions-3.7.4.3-py3.7.egg (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\requests-2.25.1-py3.7.egg (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.25.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.28.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
            "Installing collected packages: tensorflow-hub, tensorflowjs\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.11.0\n",
            "    Uninstalling tensorflow-hub-0.11.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.11.0\n",
            "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "outputs": [],
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB2AGNmJpfDK",
        "outputId": "fbc9f747-f511-47e8-df8f-5ea65cef0374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default Tensorflow\\workspace\\models\\my_ssd_mobnet\\export\\saved_model Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7rfT4-hpfDK",
        "outputId": "532707fd-6feb-4bc6-84a3-325b5d16303c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing weight file Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfjsexport\\model.json...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-04-03 11:54:23.153051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:54:25.644887: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:54:25.645576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
            "2021-04-03 11:54:25.667969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:54:25.668001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:54:25.671400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:54:25.671416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:54:25.673240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:54:25.673772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:54:25.677306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:54:25.678684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:54:25.679228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:54:25.679291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:54:25.679494: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-03 11:54:25.680122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:54:25.680135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:54:25.680141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:54:25.680148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:54:25.680152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:54:25.680158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:54:25.680163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:54:25.680167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:54:25.680171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:54:25.680197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:54:26.114383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-03 11:54:26.114403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-03 11:54:26.114407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-03 11:54:26.114533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
            "2021-04-03 11:54:26.114935: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:54:34.068925: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-04-03 11:54:34.069068: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-04-03 11:54:34.070081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:54:34.070099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:54:34.070106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:54:34.070112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:54:34.070119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:54:34.070123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:54:34.070130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:54:34.070134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:54:34.070141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:54:34.070164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:54:34.070202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-03 11:54:34.070208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-03 11:54:34.070211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-03 11:54:34.070267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
            "2021-04-03 11:54:34.070284: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:54:34.396918: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
            "  function_optimizer: Graph size after: 4000 nodes (3591), 8430 edges (8014), time = 217.05ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 4.085ms.\n",
            "\n",
            "2021-04-03 11:54:37.417793: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
            "  debug_stripper: Graph size after: 3683 nodes (0), 8201 edges (0), time = 79.922ms.\n",
            "  model_pruner: Graph size after: 3232 nodes (-451), 7750 edges (-451), time = 125.865ms.\n",
            "  constant_folding: Graph size after: 1551 nodes (-1681), 5834 edges (-1916), time = 199.089ms.\n",
            "  arithmetic_optimizer: Graph size after: 1551 nodes (0), 5834 edges (0), time = 33.234ms.\n",
            "  dependency_optimizer: Graph size after: 1453 nodes (-98), 1650 edges (-4184), time = 22.074ms.\n",
            "  model_pruner: Graph size after: 1453 nodes (0), 1650 edges (0), time = 9.534ms.\n",
            "  constant_folding: Graph size after: 1453 nodes (0), 1650 edges (0), time = 29.71ms.\n",
            "  arithmetic_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 22.603ms.\n",
            "  dependency_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 14.027ms.\n",
            "  debug_stripper: debug_stripper did nothing. time = 1.378ms.\n",
            "  model_pruner: Graph size after: 1453 nodes (0), 1650 edges (0), time = 7.504ms.\n",
            "  constant_folding: Graph size after: 1453 nodes (0), 1650 edges (0), time = 29.06ms.\n",
            "  arithmetic_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 23.745ms.\n",
            "  dependency_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 12.714ms.\n",
            "  model_pruner: Graph size after: 1453 nodes (0), 1650 edges (0), time = 8.842ms.\n",
            "  constant_folding: Graph size after: 1453 nodes (0), 1650 edges (0), time = 29.59ms.\n",
            "  arithmetic_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 23.085ms.\n",
            "  dependency_optimizer: Graph size after: 1453 nodes (0), 1650 edges (0), time = 14.073ms.\n",
            "\n",
            "2021-04-03 11:54:45.020557: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
            "  remapper: Graph size after: 1415 nodes (-114), 1308 edges (-114), time = 6.93ms.\n",
            "  constant_folding: Graph size after: 1111 nodes (-304), 1308 edges (0), time = 45.571ms.\n",
            "  arithmetic_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 18.394ms.\n",
            "  dependency_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 9.992ms.\n",
            "  remapper: Graph size after: 1111 nodes (0), 1308 edges (0), time = 5.143ms.\n",
            "  constant_folding: Graph size after: 1111 nodes (0), 1308 edges (0), time = 22.813ms.\n",
            "  arithmetic_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 18.23ms.\n",
            "  dependency_optimizer: Graph size after: 1111 nodes (0), 1308 edges (0), time = 9.571ms.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "outputs": [],
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1r5YO3rpfDL",
        "outputId": "9538d0dd-0a48-4a1e-a81c-04748634276f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py  --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --trained_checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet --output_directory=Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-xWpHN8pfDL",
        "outputId": "18de36da-abc9-4dee-bb18-c8b4f1fe7fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-16 15:36:10.485144: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f05f037bcd0>, because it is not built.\n",
            "W0116 15:36:22.296787 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f05f037bcd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f05f0248190>, because it is not built.\n",
            "W0116 15:36:22.474653 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f05f0248190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd22a50>, because it is not built.\n",
            "W0116 15:36:22.474981 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd22a50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c3bff90>, because it is not built.\n",
            "W0116 15:36:22.475177 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c3bff90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f057bd22c50>, because it is not built.\n",
            "W0116 15:36:22.475332 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f057bd22c50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bf93290>, because it is not built.\n",
            "W0116 15:36:22.475510 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bf93290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bf0a250>, because it is not built.\n",
            "W0116 15:36:22.475667 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bf0a250>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f057bcc5ad0>, because it is not built.\n",
            "W0116 15:36:22.475811 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f057bcc5ad0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bf0a110>, because it is not built.\n",
            "W0116 15:36:22.475955 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bf0a110>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c1a5d50>, because it is not built.\n",
            "W0116 15:36:22.476133 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c1a5d50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f057c26cf10>, because it is not built.\n",
            "W0116 15:36:22.476290 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f057c26cf10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd0b1d0>, because it is not built.\n",
            "W0116 15:36:22.476447 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd0b1d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd0bcd0>, because it is not built.\n",
            "W0116 15:36:22.476616 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd0bcd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f0248fd0>, because it is not built.\n",
            "W0116 15:36:22.476763 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f0248fd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057be58290>, because it is not built.\n",
            "W0116 15:36:22.476907 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057be58290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd1d610>, because it is not built.\n",
            "W0116 15:36:22.477054 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd1d610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05f006ea90>, because it is not built.\n",
            "W0116 15:36:22.477250 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05f006ea90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd12250>, because it is not built.\n",
            "W0116 15:36:22.477456 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bd12250>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c3c3310>, because it is not built.\n",
            "W0116 15:36:22.477677 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c3c3310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bfc0090>, because it is not built.\n",
            "W0116 15:36:22.477857 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bfc0090>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bf546d0>, because it is not built.\n",
            "W0116 15:36:22.478051 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bf546d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f024b050>, because it is not built.\n",
            "W0116 15:36:22.478263 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f024b050>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057beb7710>, because it is not built.\n",
            "W0116 15:36:22.478425 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057beb7710>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bade7d0>, because it is not built.\n",
            "W0116 15:36:22.478582 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bade7d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c0bcc50>, because it is not built.\n",
            "W0116 15:36:22.478733 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c0bcc50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bec0310>, because it is not built.\n",
            "W0116 15:36:22.478878 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bec0310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd2d390>, because it is not built.\n",
            "W0116 15:36:22.479022 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd2d390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057c3ac710>, because it is not built.\n",
            "W0116 15:36:22.479170 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057c3ac710>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd2db10>, because it is not built.\n",
            "W0116 15:36:22.479313 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd2db10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bdbb8d0>, because it is not built.\n",
            "W0116 15:36:22.479469 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057bdbb8d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c1e9850>, because it is not built.\n",
            "W0116 15:36:22.479611 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c1e9850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057be740d0>, because it is not built.\n",
            "W0116 15:36:22.479762 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057be740d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05f00ee9d0>, because it is not built.\n",
            "W0116 15:36:22.479914 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05f00ee9d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f00ee290>, because it is not built.\n",
            "W0116 15:36:22.480079 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f00ee290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bdc6bd0>, because it is not built.\n",
            "W0116 15:36:22.480245 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bdc6bd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f00ee0d0>, because it is not built.\n",
            "W0116 15:36:22.480389 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f00ee0d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd358d0>, because it is not built.\n",
            "W0116 15:36:22.480560 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057bd358d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f024b090>, because it is not built.\n",
            "W0116 15:36:22.480722 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f024b090>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c102750>, because it is not built.\n",
            "W0116 15:36:22.480861 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c102750>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f01fe590>, because it is not built.\n",
            "W0116 15:36:22.481005 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f01fe590>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05f01fef50>, because it is not built.\n",
            "W0116 15:36:22.481151 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f05f01fef50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f0201090>, because it is not built.\n",
            "W0116 15:36:22.481294 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f05f0201090>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c3379d0>, because it is not built.\n",
            "W0116 15:36:22.481448 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c3379d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057c337050>, because it is not built.\n",
            "W0116 15:36:22.481589 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f057c337050>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c337890>, because it is not built.\n",
            "W0116 15:36:22.572536 139666031818624 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f057c337890>, because it is not built.\n",
            "2022-01-16 15:36:35.035141: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0116 15:36:55.348406 139666031818624 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/assets\n",
            "I0116 15:37:01.963631 139666031818624 builder_impl.py:784] Assets written to: Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport/saved_model/assets\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9bJROEoGoIW"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8GwUeoFpfDL",
        "outputId": "fac43ea4-cc85-471b-a362-e994b06fd583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tflite_convert --saved_model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model --output_file=Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\\detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbd7gqHMpfDL",
        "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-04-03 11:55:38.653963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:55:41.159460: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:55:41.160164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
            "2021-04-03 11:55:41.183623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:55:41.183649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:55:41.187402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:55:41.187424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:55:41.189452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:55:41.190052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:55:41.193535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:55:41.194888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:55:41.195377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:55:41.195440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:55:41.195644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-04-03 11:55:41.196333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:55:41.196347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:55:41.196353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:55:41.196361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:55:41.196366: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:55:41.196373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:55:41.196378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:55:41.196385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:55:41.196389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:55:41.196414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:55:41.624429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-03 11:55:41.624448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-03 11:55:41.624452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-03 11:55:41.624581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
            "2021-04-03 11:55:41.624988: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:55:50.392224: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
            "2021-04-03 11:55:50.392245: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
            "2021-04-03 11:55:50.392250: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.\n",
            "2021-04-03 11:55:50.392901: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\n",
            "2021-04-03 11:55:50.467288: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
            "2021-04-03 11:55:50.467341: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\n",
            "2021-04-03 11:55:50.467439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-03 11:55:50.467446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
            "2021-04-03 11:55:50.467452: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-03 11:55:50.748887: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
            "2021-04-03 11:55:50.790035: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
            "2021-04-03 11:55:51.366069: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: Tensorflow\\workspace\\models\\my_ssd_mobnet\\tfliteexport\\saved_model\n",
            "2021-04-03 11:55:51.623706: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 1230797 microseconds.\n",
            "2021-04-03 11:55:52.694959: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2021-04-03 11:55:53.295613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
            "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
            "2021-04-03 11:55:53.295643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
            "2021-04-03 11:55:53.295652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n",
            "2021-04-03 11:55:53.295658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n",
            "2021-04-03 11:55:53.295666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
            "2021-04-03 11:55:53.295671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
            "2021-04-03 11:55:53.295678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
            "2021-04-03 11:55:53.295683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n",
            "2021-04-03 11:55:53.295689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n",
            "2021-04-03 11:55:53.295714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-03 11:55:53.295753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-03 11:55:53.295759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-03 11:55:53.295762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-03 11:55:53.295817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2b:00.0, compute capability: 7.5)\n",
            "2021-04-03 11:55:53.295834: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whShhB0x3PYJ",
        "outputId": "43cf55d3-0963-4294-e404-d9e55b751b8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjqm4Lk0gPbS"
      },
      "outputs": [],
      "source": [
        "!cp -r '/content/Tensorflow/workspace' '/content/drive/MyDrive/STAR'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2Qr5CGCh8SD"
      },
      "outputs": [],
      "source": [
        "!cp -r '/content/Tensorflow/workspace/models/my_ssd_mobnet/tfliteexport' '/content/drive/MyDrive/TFOD/NEW'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck5IG5nZigV7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "tfod"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}